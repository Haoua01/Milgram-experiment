\section{Introduction}


In the 1960s, to understand the phenomenon which transformed seemingly normal individuals into Holocaust perpetrators under the Nazi rule, Stanley Milgram conducted an experiment on destructive obedience. It demonstrated the extent to which individuals obey authority figures, even when instructed to harm others. Participants administered electric shocks to a "learner" under the guidance of an authoritative figure, with 65\% delivering the maximum shock level despite moral discomfort. This study revealed a disturbing tendency for humans to prioritize obedience over ethical considerations, particularly under authoritative pressure.


Rapid advancements in Large Language Models yields to agentic AI replicating human behavior in a sandbox environment. Hence, implementing a Milgram’s experiment in those models raises debates as to whether agents are able to contradict authoritarian figures and promote ethical considerations. 


In this paper, we aim to go beyond previous studies focusing on the simulation abilities of an agentic framework. We contribute to the existing scope of research on LLM multi-agent systems by testing the actual authoritarian relationships agents can create between them and to what extent they are influenced by other agent’s instructions. 
